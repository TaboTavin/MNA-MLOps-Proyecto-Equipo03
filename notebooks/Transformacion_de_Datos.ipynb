{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679cdba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7633a",
   "metadata": {},
   "source": [
    "## 1. Configuración y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0a5cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 52)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUTA_DATOS_ENTRADA = '/Users/tabotavin/Desktop/MNA-MLOps-Proyecto-Equipo03/data/turkish_music_emotion_modified.csv'\n",
    "RUTA_DATOS_SALIDA = '/Users/tabotavin/Desktop/MNA-MLOps-Proyecto-Equipo03/data/turkish_music_emotion_cleaned.csv'\n",
    "\n",
    "df = pd.read_csv(RUTA_DATOS_ENTRADA)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b08f5",
   "metadata": {},
   "source": [
    "## 2. Funciones Modulares de Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09704ec",
   "metadata": {},
   "source": [
    "### 2.1. Función de Análisis de Calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17a75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificar_problemas_calidad(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Identifica problemas de calidad en el dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a analizar\n",
    "        \n",
    "    Returns:\n",
    "        Diccionario con resumen de problemas identificados\n",
    "    \"\"\"\n",
    "    problemas = {\n",
    "        'columnas_extra': [],\n",
    "        'valores_invalidos': {},\n",
    "        'columnas_con_nulos': [],\n",
    "        'filas_con_problemas': 0\n",
    "    }\n",
    "    \n",
    "    # Identificar columnas que parecen no pertenecer al dataset\n",
    "    for col in df.columns:\n",
    "        # Buscar columnas con nombres poco estándar o mezcla de tipos\n",
    "        if 'mixed' in col.lower() or 'col' in col.lower():\n",
    "            problemas['columnas_extra'].append(col)\n",
    "    \n",
    "    # Identificar valores inválidos comunes\n",
    "    valores_invalidos_buscar = ['NULL', 'NaN', 'nan', 'error', 'invalid', 'bad', \n",
    "                                'unknown', '?', 'ERROR', 'N/A', '', ' ']\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            count = 0\n",
    "            for val in valores_invalidos_buscar:\n",
    "                count += (df[col] == val).sum()\n",
    "                count += df[col].str.strip().eq('').sum() if hasattr(df[col], 'str') else 0\n",
    "            \n",
    "            if count > 0:\n",
    "                problemas['valores_invalidos'][col] = count\n",
    "    \n",
    "    # Identificar columnas con valores nulos\n",
    "    nulos = df.isnull().sum()\n",
    "    problemas['columnas_con_nulos'] = nulos[nulos > 0].index.tolist()\n",
    "    \n",
    "    return problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13330d",
   "metadata": {},
   "source": [
    "### 2.2. Funciones de Limpieza de Valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29db705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_valores_invalidos(df: pd.DataFrame, columnas_excluir: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpia valores inválidos convirtiéndolos a NaN.\n",
    "    \"\"\"\n",
    "    if columnas_excluir is None:\n",
    "        columnas_excluir = []\n",
    "    \n",
    "    valores_invalidos = ['NULL', 'NaN', 'nan', 'error', 'invalid', 'bad', 'unknown', \n",
    "                        '?', 'ERROR', 'N/A', '', ' ']\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    total_convertidos = 0\n",
    "    \n",
    "    for col in df_clean.columns:\n",
    "        if col in columnas_excluir:\n",
    "            continue\n",
    "            \n",
    "        if df_clean[col].dtype == 'object':\n",
    "            mask = df_clean[col].isin(valores_invalidos)\n",
    "            if hasattr(df_clean[col], 'str'):\n",
    "                mask |= df_clean[col].str.strip().eq('')\n",
    "            \n",
    "            conversiones = mask.sum()\n",
    "            if conversiones > 0:\n",
    "                df_clean.loc[mask, col] = np.nan\n",
    "                total_convertidos += conversiones\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc226eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas_innecesarias(df: pd.DataFrame, columnas: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina columnas innecesarias del dataset.\n",
    "    \"\"\"\n",
    "    columnas_existentes = [col for col in columnas if col in df.columns]\n",
    "    if columnas_existentes:\n",
    "        df = df.drop(columns=columnas_existentes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa80357",
   "metadata": {},
   "source": [
    "### 2.3. Funciones de Gestión de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237e0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_variable_categorica(df: pd.DataFrame, columna: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normaliza una variable categórica.\n",
    "    \"\"\"\n",
    "    if columna in df.columns:\n",
    "        df[columna] = df[columna].astype(str).str.strip().str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7aaea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_a_tipos_correctos(df: pd.DataFrame, columnas_excluir: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convierte columnas a sus tipos de datos correctos.\n",
    "    \"\"\"\n",
    "    if columnas_excluir is None:\n",
    "        columnas_excluir = []\n",
    "    \n",
    "    df_typed = df.copy()\n",
    "    \n",
    "    for col in df_typed.columns:\n",
    "        if col not in columnas_excluir:\n",
    "            df_typed[col] = pd.to_numeric(df_typed[col], errors='coerce')\n",
    "    \n",
    "    return df_typed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b6df5",
   "metadata": {},
   "source": [
    "### 2.4. Funciones de Conversión de Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d0d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_filas_con_nulos_criticos(df: pd.DataFrame, columna_critica: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina filas que tienen valores nulos o inválidos en columnas críticas.\n",
    "    \"\"\"\n",
    "    filas_antes = len(df)\n",
    "    \n",
    "    df_clean = df.dropna(subset=[columna_critica])\n",
    "    \n",
    "    if df_clean[columna_critica].dtype == 'object':\n",
    "        df_clean = df_clean[~df_clean[columna_critica].astype(str).str.lower().isin(['nan', 'none', ''])]\n",
    "    \n",
    "    filas_eliminadas = filas_antes - len(df_clean)\n",
    "    print(f\"Filas eliminadas: {filas_eliminadas}\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e004e3",
   "metadata": {},
   "source": [
    "### 2.5. Funciones de Gestión de Filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d211a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_valores_faltantes(df: pd.DataFrame, metodo: str = 'mediana', \n",
    "                              columnas_excluir: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Imputa valores faltantes usando método estadístico.\n",
    "    \"\"\"\n",
    "    if columnas_excluir is None:\n",
    "        columnas_excluir = []\n",
    "    \n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    columnas_numericas = df_imputed.select_dtypes(include=[np.number]).columns\n",
    "    columnas_a_imputar = [col for col in columnas_numericas if col not in columnas_excluir]\n",
    "    \n",
    "    valores_imputados = 0\n",
    "    for col in columnas_a_imputar:\n",
    "        nulos_col = df_imputed[col].isnull().sum()\n",
    "        if nulos_col > 0:\n",
    "            if metodo == 'mediana':\n",
    "                valor_imputacion = df_imputed[col].median()\n",
    "            elif metodo == 'media':\n",
    "                valor_imputacion = df_imputed[col].mean()\n",
    "            else:\n",
    "                valor_imputacion = df_imputed[col].mode()[0]\n",
    "            \n",
    "            df_imputed[col].fillna(valor_imputacion, inplace=True)\n",
    "            valores_imputados += nulos_col\n",
    "    \n",
    "    print(f\"Valores imputados ({metodo}): {valores_imputados}\")\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88539b",
   "metadata": {},
   "source": [
    "### 2.6. Funciones de Imputación y Reportes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9269c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_reporte_limpieza(df_inicial: pd.DataFrame, df_final: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Genera reporte del proceso de limpieza.\n",
    "    \n",
    "    Args:\n",
    "        df_inicial: DataFrame antes de limpieza\n",
    "        df_final: DataFrame después de limpieza\n",
    "        \n",
    "    Returns:\n",
    "        Diccionario con métricas del proceso\n",
    "    \"\"\"\n",
    "    reporte = {\n",
    "        'filas_inicial': len(df_inicial),\n",
    "        'filas_final': len(df_final),\n",
    "        'filas_eliminadas': len(df_inicial) - len(df_final),\n",
    "        'columnas_inicial': len(df_inicial.columns),\n",
    "        'columnas_final': len(df_final.columns),\n",
    "        'columnas_eliminadas': len(df_inicial.columns) - len(df_final.columns),\n",
    "        'nulos_inicial': df_inicial.isnull().sum().sum(),\n",
    "        'nulos_final': df_final.isnull().sum().sum(),\n",
    "        'tasa_retencion': (len(df_final) / len(df_inicial) * 100) if len(df_inicial) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return reporte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2bc6",
   "metadata": {},
   "source": [
    "## 3. Análisis Inicial de Datos Corruptos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd632add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas extra: ['mixed_type_col']\n",
      "Columnas con valores inválidos: 35\n",
      "Columnas con nulos: 52\n"
     ]
    }
   ],
   "source": [
    "df_original = df.copy()\n",
    "\n",
    "problemas = identificar_problemas_calidad(df)\n",
    "\n",
    "print(f\"Columnas extra: {problemas['columnas_extra']}\")\n",
    "print(f\"Columnas con valores inválidos: {len(problemas['valores_invalidos'])}\")\n",
    "print(f\"Columnas con nulos: {len(problemas['columnas_con_nulos'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71ffd1",
   "metadata": {},
   "source": [
    "## 4. Ejecución del Pipeline de Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c115f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas: ['mixed_type_col']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(408, 51)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 1: Eliminar columnas innecesarias\n",
    "if problemas['columnas_extra']:\n",
    "    df = eliminar_columnas_innecesarias(df, problemas['columnas_extra'])\n",
    "    print(f\"Columnas eliminadas: {problemas['columnas_extra']}\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fe8d533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['relax', 'happy', 'sad', 'angry', 'nan'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 2: Normalizar variable objetivo\n",
    "df = normalizar_variable_categorica(df, 'Class')\n",
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902a319f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(295)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 3: Limpiar valores inválidos\n",
    "df = limpiar_valores_invalidos(df, columnas_excluir=['Class'])\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d859bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    50\n",
       "object      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 4: Convertir a tipos de datos correctos\n",
    "df = convertir_a_tipos_correctos(df, columnas_excluir=['Class'])\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b00914a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas eliminadas: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(403, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 5: Eliminar filas con problemas críticos en variable objetivo\n",
    "df = eliminar_filas_con_nulos_criticos(df, 'Class')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86870cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores imputados (mediana): 298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso 6: Imputar valores faltantes\n",
    "df = imputar_valores_faltantes(df, metodo='mediana', columnas_excluir=['Class'])\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5949b59",
   "metadata": {},
   "source": [
    "## 5. Validación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05cfddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (403, 51)\n",
      "Valores nulos: 0\n",
      "Valores duplicados: 2\n",
      "\n",
      "Variable objetivo - Valores únicos: 4\n",
      "  relax: 102 (25.3%)\n",
      "  happy: 102 (25.3%)\n",
      "  sad: 102 (25.3%)\n",
      "  angry: 97 (24.1%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensiones: {df.shape}\")\n",
    "print(f\"Valores nulos: {df.isnull().sum().sum()}\")\n",
    "print(f\"Valores duplicados: {df.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\nVariable objetivo - Valores únicos: {df['Class'].nunique()}\")\n",
    "for clase, count in df['Class'].value_counts().items():\n",
    "    print(f\"  {clase}: {count} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb97fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_RMSenergy_Mean</th>\n",
       "      <td>3.2873</td>\n",
       "      <td>47.5225</td>\n",
       "      <td>0.010</td>\n",
       "      <td>873.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Tempo_Mean</th>\n",
       "      <td>153.1517</td>\n",
       "      <td>601.4155</td>\n",
       "      <td>48.284</td>\n",
       "      <td>12177.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Brightness_Mean</th>\n",
       "      <td>5.9359</td>\n",
       "      <td>64.1229</td>\n",
       "      <td>0.053</td>\n",
       "      <td>852.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Spectralcentroid_Mean</th>\n",
       "      <td>4612.9601</td>\n",
       "      <td>21684.0952</td>\n",
       "      <td>606.524</td>\n",
       "      <td>318051.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Eventdensity_Mean</th>\n",
       "      <td>8.8927</td>\n",
       "      <td>67.5416</td>\n",
       "      <td>0.234</td>\n",
       "      <td>998.241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean         std      min         max\n",
       "_RMSenergy_Mean            3.2873     47.5225    0.010     873.096\n",
       "_Tempo_Mean              153.1517    601.4155   48.284   12177.714\n",
       "_Brightness_Mean           5.9359     64.1229    0.053     852.419\n",
       "_Spectralcentroid_Mean  4612.9601  21684.0952  606.524  318051.072\n",
       "_Eventdensity_Mean         8.8927     67.5416    0.234     998.241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columnas_muestra = ['_RMSenergy_Mean', '_Tempo_Mean', '_Brightness_Mean', \n",
    "                    '_Spectralcentroid_Mean', '_Eventdensity_Mean']\n",
    "\n",
    "columnas_disponibles = [col for col in columnas_muestra if col in df.columns]\n",
    "\n",
    "if columnas_disponibles:\n",
    "    stats_df = df[columnas_disponibles].describe().T\n",
    "    stats_df = stats_df[['mean', 'std', 'min', 'max']].round(4)\n",
    "    display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90d06e",
   "metadata": {},
   "source": [
    "## 6. Exportación del Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bda63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RUTA_DATOS_SALIDA, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNA-MLOps-Proyecto-Equipo03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
